{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caedae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "# 1. Setup and Imports\n",
    "#---------------------------------------------------------------------\n",
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import requests\n",
    "import openai\n",
    "import chromadb\n",
    "from getpass import getpass\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bcceac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- API Key Configuration ---\n",
    "load_dotenv()\n",
    "\n",
    "OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Prompt for keys if not found in environment\n",
    "if not OPENROUTER_API_KEY:\n",
    "    print(\"Warning: OpenRouter API key not found in .env. Attempting to prompt.\")\n",
    "    OPENROUTER_API_KEY = getpass(\"Please enter your OpenRouter API key: \")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"Warning: OpenAI API key not found in .env. Attempting to prompt.\")\n",
    "    OPENAI_API_KEY = getpass(\"Please enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c31aeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenRouter API key loaded: True\n",
      "OpenAI API key loaded: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"OpenRouter API key loaded: {bool(OPENROUTER_API_KEY)}\")\n",
    "print(f\"OpenAI API key loaded: {bool(OPENAI_API_KEY)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca652555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99308bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration Constants ---\n",
    "OPENROUTER_API_BASE = \"https://openrouter.ai/api/v1\"\n",
    "LLM_MODEL = \"google/gemini-flash-1.5-8b\"  # For reasoning\n",
    "EMBEDDING_MODEL = \"text-embedding-3-large\"  # OpenAI embeddings\n",
    "LLM_TEMPERATURE = 0.2  # Low temperature for predictable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "113447b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Database Configuration ---\n",
    "SQLITE_DB_PATH = \"./simple_knowledge_graph.db\"\n",
    "CHROMA_DB_PATH = \"./simple_chroma_memories\"\n",
    "CHROMA_COLLECTION_NAME = \"simple_user_memories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9db78c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI client initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# --- OpenAI Client Initialization ---\n",
    "openai_client = None\n",
    "if OPENAI_API_KEY:\n",
    "    try:\n",
    "        openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "        openai_client.models.list()  # Test call\n",
    "        print(\"✓ OpenAI client initialized successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error initializing OpenAI client: {e}\")\n",
    "        openai_client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7fd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ChromaDB Initialization ---\n",
    "chroma_client = None\n",
    "memory_collection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d196e344",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ChromaDB client initialized with collection 'simple_user_memories'\n",
      "Current items in ChromaDB collection: 0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "    memory_collection = chroma_client.get_or_create_collection(\n",
    "        name=CHROMA_COLLECTION_NAME,\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    print(f\"✓ ChromaDB client initialized with collection '{CHROMA_COLLECTION_NAME}'\")\n",
    "    print(f\"Current items in ChromaDB collection: {memory_collection.count()}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error initializing ChromaDB: {e}\")\n",
    "    chroma_client = None\n",
    "    memory_collection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4c707a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "# 2. Knowledge Graph Database Setup\n",
    "#---------------------------------------------------------------------\n",
    "@contextmanager\n",
    "def get_db_connection():\n",
    "    \"\"\"Provides a database connection context.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(SQLITE_DB_PATH)\n",
    "        conn.row_factory = sqlite3.Row  # Return rows as dict-like objects\n",
    "        yield conn\n",
    "    except Exception as e:\n",
    "        print(f\"Database connection error: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24731aa9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def init_db():\n",
    "    \"\"\"Initializes the SQLite database schema for the knowledge graph.\"\"\"\n",
    "    try:\n",
    "        with get_db_connection() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Nodes table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS nodes (\n",
    "                    node_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    name TEXT NOT NULL UNIQUE,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            # Node attributes table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS node_attributes (\n",
    "                    attribute_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    node_id INTEGER NOT NULL,\n",
    "                    attribute_key TEXT NOT NULL,\n",
    "                    attribute_value TEXT NOT NULL,\n",
    "                    FOREIGN KEY (node_id) REFERENCES nodes (node_id) ON DELETE CASCADE,\n",
    "                    UNIQUE(node_id, attribute_key)\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            # Relationships table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS relationships (\n",
    "                    relationship_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    source_node_id INTEGER NOT NULL,\n",
    "                    target_node_id INTEGER NOT NULL,\n",
    "                    relationship_type TEXT NOT NULL,\n",
    "                    FOREIGN KEY (source_node_id) REFERENCES nodes (node_id) ON DELETE CASCADE,\n",
    "                    FOREIGN KEY (target_node_id) REFERENCES nodes (node_id) ON DELETE CASCADE,\n",
    "                    UNIQUE(source_node_id, target_node_id, relationship_type)\n",
    "                )\n",
    "            \"\"\")\n",
    "            \n",
    "            # Create indexes for faster lookups\n",
    "            cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_node_name ON nodes (name)\")\n",
    "            cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_attribute_node_id ON node_attributes (node_id)\")\n",
    "            cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_relationship_source ON relationships (source_node_id)\")\n",
    "            cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_relationship_target ON relationships (target_node_id)\")\n",
    "            \n",
    "            conn.commit()\n",
    "            print(\"✓ Database schema initialized successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Database initialization error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc5d7543",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Database schema initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize the database\n",
    "init_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf86df",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------\n",
    "3. Core Utility Functions\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3612b2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def call_llm(messages: List[Dict[str, str]], temperature: float = LLM_TEMPERATURE) -> Optional[str]:\n",
    "    \"\"\"Calls the LLM with the provided messages.\"\"\"\n",
    "    if not OPENROUTER_API_KEY:\n",
    "        print(\"OpenRouter API key is not set\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{OPENROUTER_API_BASE}/chat/completions\",\n",
    "            headers={\n",
    "                \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "            },\n",
    "            json={\n",
    "                \"model\": LLM_MODEL,\n",
    "                \"messages\": messages,\n",
    "                \"temperature\": temperature,\n",
    "                \"max_tokens\": 500,\n",
    "            },\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error calling LLM: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84d0412a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> Optional[np.ndarray]:\n",
    "    \"\"\"Gets embedding for text using OpenAI's embedding model.\"\"\"\n",
    "    if not openai_client:\n",
    "        print(\"OpenAI client not initialized, cannot get embeddings\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        text_to_embed = text.replace(\"\\n\", \" \")\n",
    "        response = openai_client.embeddings.create(\n",
    "            input=[text_to_embed],\n",
    "            model=EMBEDDING_MODEL,\n",
    "        )\n",
    "        return np.array(response.data[0].embedding)\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1252b7",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------\n",
    "4. Knowledge Graph Core Functions\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd87147b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_node_by_name(node_name: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Retrieves a node by its name.\"\"\"\n",
    "    try:\n",
    "        with get_db_connection() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT node_id, name FROM nodes WHERE name = ?\", (node_name,))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                return dict(result)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting node by name: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0710f2e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def add_node(node_name: str, text_content: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Adds a node to both SQLite and ChromaDB.\n",
    "    Returns node_id if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First check if node already exists\n",
    "        existing_node = get_node_by_name(node_name)\n",
    "        if existing_node:\n",
    "            return existing_node['node_id']\n",
    "        \n",
    "        # Add to SQLite\n",
    "        with get_db_connection() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"INSERT INTO nodes (name) VALUES (?)\", (node_name,))\n",
    "            node_id = cursor.lastrowid\n",
    "            \n",
    "            # Add text content as an attribute\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO node_attributes (node_id, attribute_key, attribute_value) VALUES (?, ?, ?)\",\n",
    "                (node_id, \"text\", text_content)\n",
    "            )\n",
    "            conn.commit()\n",
    "            \n",
    "        # Add to ChromaDB with embedding\n",
    "        embedding = get_embedding(text_content)\n",
    "        if embedding is not None and memory_collection:\n",
    "            memory_collection.add(\n",
    "                ids=[str(node_id)],\n",
    "                embeddings=[embedding.tolist()],\n",
    "                documents=[text_content],\n",
    "                metadatas=[{\"node_name\": node_name}]\n",
    "            )\n",
    "        \n",
    "        print(f\"✓ Added node '{node_name}' with ID {node_id}\")\n",
    "        return node_id\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error adding node: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da61445",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def add_relationship(source_name: str, target_name: str, relationship_type: str) -> bool:\n",
    "    \"\"\"Adds a relationship between two nodes.\"\"\"\n",
    "    try:\n",
    "        source_node = get_node_by_name(source_name)\n",
    "        target_node = get_node_by_name(target_name)\n",
    "        \n",
    "        if not source_node:\n",
    "            print(f\"Source node '{source_name}' not found\")\n",
    "            return False\n",
    "        if not target_node:\n",
    "            print(f\"Target node '{target_name}' not found\")\n",
    "            return False\n",
    "            \n",
    "        with get_db_connection() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            try:\n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO relationships (source_node_id, target_node_id, relationship_type) VALUES (?, ?, ?)\",\n",
    "                    (source_node['node_id'], target_node['node_id'], relationship_type)\n",
    "                )\n",
    "                conn.commit()\n",
    "                print(f\"✓ Added relationship: {source_name} --[{relationship_type}]--> {target_name}\")\n",
    "                return True\n",
    "            except sqlite3.IntegrityError:\n",
    "                # Relationship already exists\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error adding relationship: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4463c46f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_node_attributes(node_name: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Gets all attributes for a node.\"\"\"\n",
    "    attributes = []\n",
    "    try:\n",
    "        node = get_node_by_name(node_name)\n",
    "        if not node:\n",
    "            return []\n",
    "            \n",
    "        with get_db_connection() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\n",
    "                \"SELECT attribute_key, attribute_value FROM node_attributes WHERE node_id = ?\",\n",
    "                (node['node_id'],)\n",
    "            )\n",
    "            for row in cursor.fetchall():\n",
    "                attributes.append(dict(row))\n",
    "        return attributes\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting node attributes: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d00fd8c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def find_related_nodes(node_name: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Finds all nodes related to this node via relationships.\"\"\"\n",
    "    related_nodes = []\n",
    "    try:\n",
    "        node = get_node_by_name(node_name)\n",
    "        if not node:\n",
    "            return []\n",
    "            \n",
    "        with get_db_connection() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Find outgoing relationships\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT r.relationship_type, n.node_id, n.name\n",
    "                FROM relationships r\n",
    "                JOIN nodes n ON r.target_node_id = n.node_id\n",
    "                WHERE r.source_node_id = ?\n",
    "            \"\"\", (node['node_id'],))\n",
    "            \n",
    "            for row in cursor.fetchall():\n",
    "                related_nodes.append({\n",
    "                    \"node_name\": row['name'],\n",
    "                    \"node_id\": row['node_id'],\n",
    "                    \"relationship\": row['relationship_type'],\n",
    "                    \"direction\": \"outgoing\"\n",
    "                })\n",
    "                \n",
    "            # Find incoming relationships\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT r.relationship_type, n.node_id, n.name\n",
    "                FROM relationships r\n",
    "                JOIN nodes n ON r.source_node_id = n.node_id\n",
    "                WHERE r.target_node_id = ?\n",
    "            \"\"\", (node['node_id'],))\n",
    "            \n",
    "            for row in cursor.fetchall():\n",
    "                related_nodes.append({\n",
    "                    \"node_name\": row['name'],\n",
    "                    \"node_id\": row['node_id'],\n",
    "                    \"relationship\": row['relationship_type'],\n",
    "                    \"direction\": \"incoming\"\n",
    "                })\n",
    "                \n",
    "        return related_nodes\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error finding related nodes: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7405799",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_node_text(node_name: str) -> Optional[str]:\n",
    "    \"\"\"Gets the text content of a node.\"\"\"\n",
    "    attributes = get_node_attributes(node_name)\n",
    "    for attr in attributes:\n",
    "        if attr['attribute_key'] == 'text':\n",
    "            return attr['attribute_value']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79aa3ebb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def semantic_search(query_text: str, top_n: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Performs semantic search in ChromaDB.\"\"\"\n",
    "    if not memory_collection:\n",
    "        print(\"ChromaDB collection not available\")\n",
    "        return []\n",
    "        \n",
    "    embedding = get_embedding(query_text)\n",
    "    if embedding is None:\n",
    "        print(\"Failed to get embedding for query\")\n",
    "        return []\n",
    "        \n",
    "    try:\n",
    "        results = memory_collection.query(\n",
    "            query_embeddings=[embedding.tolist()],\n",
    "            n_results=top_n,\n",
    "            include=['documents', 'metadatas', 'distances']\n",
    "        )\n",
    "        \n",
    "        similar_items = []\n",
    "        if results and 'ids' in results and results['ids'] and results['ids'][0]:\n",
    "            for i, doc_id in enumerate(results['ids'][0]):\n",
    "                distance = results['distances'][0][i] if 'distances' in results and results['distances'][0] else None\n",
    "                similarity = (1 - distance) if distance is not None else 0.0\n",
    "                \n",
    "                node_name = results['metadatas'][0][i].get('node_name') if 'metadatas' in results else f\"node_{doc_id}\"\n",
    "                \n",
    "                similar_items.append({\n",
    "                    'id': doc_id,\n",
    "                    'node_name': node_name,\n",
    "                    'text': results['documents'][0][i] if 'documents' in results and results['documents'][0] else None,\n",
    "                    'similarity': similarity\n",
    "                })\n",
    "        return similar_items\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error in semantic search: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc59d4fc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_all_nodes() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Gets all nodes in the graph database.\"\"\"\n",
    "    try:\n",
    "        with get_db_connection() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT node_id, name FROM nodes\")\n",
    "            return [dict(row) for row in cursor.fetchall()]\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error getting all nodes: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42444504",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------\n",
    "5. Core Data Setup\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cee93a0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def setup_core_memories():\n",
    "    \"\"\"Setup the core structured memories.\"\"\"\n",
    "    # Check if we already have data\n",
    "    existing_nodes = get_all_nodes()\n",
    "    if existing_nodes:\n",
    "        print(f\"✓ Database already contains {len(existing_nodes)} nodes. Skipping setup.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Setting up core memories...\")\n",
    "    \n",
    "    # Core memories\n",
    "    memories = [\n",
    "        # Pet-related cluster\n",
    "        {\"name\": \"Dog_Arlo\", \"text\": \"My dog Arlo is a golden retriever.\"},\n",
    "        {\"name\": \"Arlo_Anxiety\", \"text\": \"Arlo gets very anxious if left with strangers for too long.\"},\n",
    "        {\"name\": \"Sister_Pet_Sitting\", \"text\": \"I only trust my sister, Chloe, to watch Arlo when I travel.\"},\n",
    "        {\"name\": \"Chloe_Trip\", \"text\": \"Chloe is planning a big trip to Europe for all of July.\"},\n",
    "        \n",
    "        # Travel preferences\n",
    "        {\"name\": \"Travel_Budget\", \"text\": \"I have a strict travel budget of $1000 for my next trip.\"},\n",
    "        {\"name\": \"Hotel_Preference\", \"text\": \"I prefer boutique hotels over large chain hotels.\"},\n",
    "        {\"name\": \"Expensive_Boutique\", \"text\": \"Boutique hotels in major cities tend to be quite expensive.\"},\n",
    "        \n",
    "        # Diving related\n",
    "        {\"name\": \"Scuba_Hobby\", \"text\": \"I love scuba diving and want to do it on my next beach holiday.\"},\n",
    "        {\"name\": \"Recent_Ear_Infection\", \"text\": \"I recently had a minor ear infection.\"},\n",
    "        {\"name\": \"Diving_Restriction\", \"text\": \"My doctor advised me to avoid diving for at least 6 weeks after an ear infection.\"},\n",
    "        \n",
    "        # Japan related\n",
    "        {\"name\": \"Japan_Interest\", \"text\": \"I dream of visiting Japan for the cherry blossom season.\"},\n",
    "        {\"name\": \"Cherry_Blossom_Season\", \"text\": \"Cherry blossom season in Japan is typically late March to April.\"},\n",
    "        {\"name\": \"Flying_Fear\", \"text\": \"I'm quite scared of flying long distances.\"},\n",
    "        {\"name\": \"Japan_Flight_Duration\", \"text\": \"Flights to Japan from my home are usually over 12 hours long.\"},\n",
    "        \n",
    "        # Dietary\n",
    "        {\"name\": \"Lactose_Intolerance\", \"text\": \"I'm lactose intolerant and avoid dairy products strictly.\"},\n",
    "        {\"name\": \"Italian_Wedding\", \"text\": \"My friend's wedding is next month, and it's a traditional Italian feast.\"},\n",
    "        {\"name\": \"Italian_Food\", \"text\": \"Traditional Italian feasts often feature a lot of cheese and cream-based sauces.\"},\n",
    "        \n",
    "        # Professional\n",
    "        {\"name\": \"Company_Expansion\", \"text\": \"My company is expanding into South America soon.\"},\n",
    "        {\"name\": \"Learning_Spanish\", \"text\": \"I want to learn Spanish to improve my career prospects.\"},\n",
    "        {\"name\": \"Language_Learning\", \"text\": \"Immersion is the best way to learn a language quickly.\"}\n",
    "    ]\n",
    "    \n",
    "    # Add all nodes first\n",
    "    for memory in memories:\n",
    "        add_node(memory[\"name\"], memory[\"text\"])\n",
    "    \n",
    "    # Add relationships\n",
    "    relationships = [\n",
    "        # Pet relationships\n",
    "        (\"Dog_Arlo\", \"Arlo_Anxiety\", \"has_behavior\"),\n",
    "        (\"Dog_Arlo\", \"Sister_Pet_Sitting\", \"cared_by\"),\n",
    "        (\"Sister_Pet_Sitting\", \"Chloe_Trip\", \"affected_by\"),\n",
    "        \n",
    "        # Travel constraints\n",
    "        (\"Scuba_Hobby\", \"Recent_Ear_Infection\", \"constrained_by\"),\n",
    "        (\"Recent_Ear_Infection\", \"Diving_Restriction\", \"leads_to\"),\n",
    "        (\"Japan_Interest\", \"Cherry_Blossom_Season\", \"during\"),\n",
    "        (\"Japan_Interest\", \"Flying_Fear\", \"limited_by\"),\n",
    "        (\"Flying_Fear\", \"Japan_Flight_Duration\", \"triggered_by\"),\n",
    "        (\"Travel_Budget\", \"Hotel_Preference\", \"influences\"),\n",
    "        (\"Hotel_Preference\", \"Expensive_Boutique\", \"relates_to\"),\n",
    "        \n",
    "        # Dietary constraints\n",
    "        (\"Lactose_Intolerance\", \"Italian_Wedding\", \"complicates\"),\n",
    "        (\"Italian_Wedding\", \"Italian_Food\", \"features\"),\n",
    "        \n",
    "        # Professional\n",
    "        (\"Company_Expansion\", \"Learning_Spanish\", \"motivates\"),\n",
    "        (\"Learning_Spanish\", \"Language_Learning\", \"method\")\n",
    "    ]\n",
    "    \n",
    "    for source, target, relation in relationships:\n",
    "        add_relationship(source, target, relation)\n",
    "        \n",
    "    print(f\"✓ Core memories setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd42016",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------\n",
    "6. Graph Exploration and Memory Retrieval \n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f307163b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def retrieve_relevant_memories(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Main function to retrieve relevant memories for a user query.\n",
    "    Uses a multi-step approach with graph exploration.\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing query: '{query}'\")\n",
    "    exploration_history = []\n",
    "    \n",
    "    # Step 1: Initial semantic search to find starting points\n",
    "    print(\"\\nStep 1: Performing initial semantic search\")\n",
    "    semantic_matches = semantic_search(query, top_n=3)\n",
    "    \n",
    "    initial_candidates = []\n",
    "    for match in semantic_matches:\n",
    "        print(f\"Found semantic match: {match['node_name']} (similarity: {match['similarity']:.3f})\")\n",
    "        initial_candidates.append({\n",
    "            \"node_name\": match['node_name'],\n",
    "            \"text\": match['text'],\n",
    "            \"similarity\": match['similarity'],\n",
    "            \"explored\": False\n",
    "        })\n",
    "        exploration_history.append({\n",
    "            \"step\": \"initial_search\", \n",
    "            \"node\": match['node_name'],\n",
    "            \"text\": match['text'],\n",
    "            \"similarity\": match['similarity']\n",
    "        })\n",
    "    \n",
    "    if not initial_candidates:\n",
    "        print(\"  No initial matches found\")\n",
    "        return []\n",
    "\n",
    "    # Step 2: Explore the graph from the initial candidates\n",
    "    print(\"\\n🔍 Step 2: Exploring graph from initial matches\")\n",
    "    all_candidates = {}  # Using dict to avoid duplicates, keyed by node_name\n",
    "    \n",
    "    # Add initial candidates\n",
    "    for candidate in initial_candidates:\n",
    "        all_candidates[candidate['node_name']] = candidate\n",
    "    \n",
    "    # Explore outward from initial candidates\n",
    "    explored_count = 0\n",
    "    max_explore = 10  # Limit exploration to avoid crawling too far\n",
    "    \n",
    "    while explored_count < max_explore:\n",
    "        # Find unexplored candidate with highest similarity\n",
    "        current = None\n",
    "        for node_name, candidate in all_candidates.items():\n",
    "            if not candidate['explored']:\n",
    "                if current is None or candidate['similarity'] > current['similarity']:\n",
    "                    current = candidate\n",
    "        \n",
    "        if current is None:\n",
    "            break  # All candidates explored\n",
    "            \n",
    "        # Mark as explored\n",
    "        all_candidates[current['node_name']]['explored'] = True\n",
    "        explored_count += 1\n",
    "        \n",
    "        print(f\"  Exploring from: {current['node_name']}\")\n",
    "        \n",
    "        # Find related nodes\n",
    "        related = find_related_nodes(current['node_name'])\n",
    "        for node in related:\n",
    "            related_node_name = node['node_name']\n",
    "            relationship = node['relationship']\n",
    "            direction = node['direction']\n",
    "            \n",
    "            rel_str = f\"--[{relationship}]-->\" if direction == \"outgoing\" else \"<--[{relationship}]--\"\n",
    "            print(f\"    Related: {current['node_name']} {rel_str} {related_node_name}\")\n",
    "            \n",
    "            # Skip if already in candidates\n",
    "            if related_node_name in all_candidates:\n",
    "                continue\n",
    "                \n",
    "            # Get text for related node\n",
    "            text = get_node_text(related_node_name)\n",
    "            if not text:\n",
    "                continue\n",
    "                \n",
    "            # Calculate relatedness score (decaying sim score based on distance)\n",
    "            relatedness = max(0.1, current['similarity'] * 0.8)  # Decay factor\n",
    "            \n",
    "            # Add to candidates\n",
    "            all_candidates[related_node_name] = {\n",
    "                \"node_name\": related_node_name,\n",
    "                \"text\": text,\n",
    "                \"similarity\": relatedness,\n",
    "                \"explored\": False,\n",
    "                \"connected_via\": current['node_name'],\n",
    "                \"relationship\": relationship,\n",
    "                \"direction\": direction\n",
    "            }\n",
    "            \n",
    "            exploration_history.append({\n",
    "                \"step\": \"graph_exploration\",\n",
    "                \"source\": current['node_name'],\n",
    "                \"target\": related_node_name,\n",
    "                \"relationship\": relationship,\n",
    "                \"direction\": direction,\n",
    "                \"text\": text,\n",
    "                \"similarity\": relatedness\n",
    "            })\n",
    "    \n",
    "    # Step 3: Filter candidates with LLM\n",
    "    print(f\"\\nStep 3: Evaluating {len(all_candidates)} candidates for relevance\")\n",
    "    \n",
    "    # Format candidates for LLM\n",
    "    candidates_formatted = \"\\n\".join([\n",
    "        f\"- {c['node_name']}: {c['text']}\" for c in all_candidates.values()\n",
    "    ])\n",
    "    \n",
    "    filter_prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that evaluates which memories are most relevant to answering a user's query.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"I need to answer this query: \"{query}\"\n",
    "         Here are memories that might be relevant:\n",
    "         {candidates_formatted}\n",
    "         \n",
    "         Please list ONLY the node names of the 3-5 most relevant memories for answering this query.\n",
    "         Format your response as a JSON array of strings containing only the node names.\n",
    "         Example: [\"Node1\", \"Node2\", \"Node3\"]\"\"\"}]\n",
    "    \n",
    "    llm_response = call_llm(filter_prompt, temperature=0.1)\n",
    "    \n",
    "    if not llm_response:\n",
    "        print(\"  ✗ Failed to get LLM response for filtering\")\n",
    "        # Fallback: return candidates sorted by similarity\n",
    "        sorted_candidates = sorted(all_candidates.values(), key=lambda x: x['similarity'], reverse=True)\n",
    "        return sorted_candidates[:3]\n",
    "    \n",
    "    try:\n",
    "        # Extract relevant nodes from LLM response\n",
    "        # First, strip any non-JSON content and find the actual JSON array\n",
    "        clean_response = llm_response.strip()\n",
    "        \n",
    "        # Try to find JSON array pattern\n",
    "        import re\n",
    "        json_match = re.search(r'\\[.*?\\]', clean_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            clean_response = json_match.group(0)\n",
    "        \n",
    "        relevant_node_names = json.loads(clean_response)\n",
    "        if not isinstance(relevant_node_names, list):\n",
    "            raise ValueError(\"Expected list in JSON response\")\n",
    "            \n",
    "        print(f\"  LLM selected {len(relevant_node_names)} relevant memories\")\n",
    "        \n",
    "        # Get full details for selected nodes\n",
    "        relevant_memories = []\n",
    "        for node_name in relevant_node_names:\n",
    "            if node_name in all_candidates:\n",
    "                relevant_memories.append(all_candidates[node_name])\n",
    "            \n",
    "        return relevant_memories\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error parsing LLM response: {e}\")\n",
    "        print(f\"  LLM response was: {llm_response}\")\n",
    "        \n",
    "        # Try to extract node names from text if JSON parsing failed\n",
    "        extracted_nodes = []\n",
    "        if llm_response:  # Check if response exists\n",
    "            for line in llm_response.split(\"\\n\"):\n",
    "                for cand_name in all_candidates.keys():\n",
    "                    if cand_name in line:\n",
    "                        extracted_nodes.append(cand_name)\n",
    "        \n",
    "            if extracted_nodes:\n",
    "                relevant_memories = []\n",
    "                for node_name in extracted_nodes:\n",
    "                    relevant_memories.append(all_candidates[node_name])\n",
    "                return relevant_memories\n",
    "        \n",
    "        # Last fallback: return candidates sorted by similarity\n",
    "        sorted_candidates = sorted(all_candidates.values(), key=lambda x: x['similarity'], reverse=True)\n",
    "        return sorted_candidates[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae37ce",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------\n",
    "7. Example Usage\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cf0d552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Database already contains 20 nodes. Skipping setup.\n",
      "\n",
      "================================================================================\n",
      " STANDARD EXAMPLES\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      " EXAMPLE 1: Any ideas for a holiday in July?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'Any ideas for a holiday in July?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Chloe_Trip (similarity: 0.473)\n",
      "Found semantic match: Scuba_Hobby (similarity: 0.298)\n",
      "Found semantic match: Travel_Budget (similarity: 0.251)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Chloe_Trip\n",
      "    Related: Chloe_Trip <--[{relationship}]-- Sister_Pet_Sitting\n",
      "  Exploring from: Sister_Pet_Sitting\n",
      "    Related: Sister_Pet_Sitting --[affected_by]--> Chloe_Trip\n",
      "    Related: Sister_Pet_Sitting <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Dog_Arlo\n",
      "    Related: Dog_Arlo --[has_behavior]--> Arlo_Anxiety\n",
      "    Related: Dog_Arlo --[cared_by]--> Sister_Pet_Sitting\n",
      "  Exploring from: Scuba_Hobby\n",
      "    Related: Scuba_Hobby --[constrained_by]--> Recent_Ear_Infection\n",
      "  Exploring from: Travel_Budget\n",
      "    Related: Travel_Budget --[influences]--> Hotel_Preference\n",
      "  Exploring from: Arlo_Anxiety\n",
      "    Related: Arlo_Anxiety <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Recent_Ear_Infection\n",
      "    Related: Recent_Ear_Infection --[leads_to]--> Diving_Restriction\n",
      "    Related: Recent_Ear_Infection <--[{relationship}]-- Scuba_Hobby\n",
      "  Exploring from: Hotel_Preference\n",
      "    Related: Hotel_Preference --[relates_to]--> Expensive_Boutique\n",
      "    Related: Hotel_Preference <--[{relationship}]-- Travel_Budget\n",
      "  Exploring from: Diving_Restriction\n",
      "    Related: Diving_Restriction <--[{relationship}]-- Recent_Ear_Infection\n",
      "  Exploring from: Expensive_Boutique\n",
      "    Related: Expensive_Boutique <--[{relationship}]-- Hotel_Preference\n",
      "\n",
      "Step 3: Evaluating 10 candidates for relevance\n",
      "  LLM selected 4 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "1. Scuba_Hobby: I love scuba diving and want to do it on my next beach holiday.\n",
      "2. Travel_Budget: I have a strict travel budget of $1000 for my next trip.\n",
      "3. Hotel_Preference: I prefer boutique hotels over large chain hotels.\n",
      "4. Diving_Restriction: My doctor advised me to avoid diving for at least 6 weeks after an ear infection.\n",
      "\n",
      "======================================================================\n",
      " EXAMPLE 2: I want to go scuba diving on my next vacation.\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'I want to go scuba diving on my next vacation.'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Scuba_Hobby (similarity: 0.842)\n",
      "Found semantic match: Travel_Budget (similarity: 0.351)\n",
      "Found semantic match: Diving_Restriction (similarity: 0.350)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Scuba_Hobby\n",
      "    Related: Scuba_Hobby --[constrained_by]--> Recent_Ear_Infection\n",
      "  Exploring from: Recent_Ear_Infection\n",
      "    Related: Recent_Ear_Infection --[leads_to]--> Diving_Restriction\n",
      "    Related: Recent_Ear_Infection <--[{relationship}]-- Scuba_Hobby\n",
      "  Exploring from: Travel_Budget\n",
      "    Related: Travel_Budget --[influences]--> Hotel_Preference\n",
      "  Exploring from: Diving_Restriction\n",
      "    Related: Diving_Restriction <--[{relationship}]-- Recent_Ear_Infection\n",
      "  Exploring from: Hotel_Preference\n",
      "    Related: Hotel_Preference --[relates_to]--> Expensive_Boutique\n",
      "    Related: Hotel_Preference <--[{relationship}]-- Travel_Budget\n",
      "  Exploring from: Expensive_Boutique\n",
      "    Related: Expensive_Boutique <--[{relationship}]-- Hotel_Preference\n",
      "\n",
      "Step 3: Evaluating 6 candidates for relevance\n",
      "  LLM selected 4 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "1. Scuba_Hobby: I love scuba diving and want to do it on my next beach holiday.\n",
      "2. Travel_Budget: I have a strict travel budget of $1000 for my next trip.\n",
      "3. Diving_Restriction: My doctor advised me to avoid diving for at least 6 weeks after an ear infection.\n",
      "4. Recent_Ear_Infection: I recently had a minor ear infection.\n",
      "\n",
      "======================================================================\n",
      " EXAMPLE 3: What should I know about attending my friend's Italian wedding?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'What should I know about attending my friend's Italian wedding?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Italian_Wedding (similarity: 0.642)\n",
      "Found semantic match: Italian_Food (similarity: 0.383)\n",
      "Found semantic match: Chloe_Trip (similarity: 0.222)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Italian_Wedding\n",
      "    Related: Italian_Wedding --[features]--> Italian_Food\n",
      "    Related: Italian_Wedding <--[{relationship}]-- Lactose_Intolerance\n",
      "  Exploring from: Lactose_Intolerance\n",
      "    Related: Lactose_Intolerance --[complicates]--> Italian_Wedding\n",
      "  Exploring from: Italian_Food\n",
      "    Related: Italian_Food <--[{relationship}]-- Italian_Wedding\n",
      "  Exploring from: Chloe_Trip\n",
      "    Related: Chloe_Trip <--[{relationship}]-- Sister_Pet_Sitting\n",
      "  Exploring from: Sister_Pet_Sitting\n",
      "    Related: Sister_Pet_Sitting --[affected_by]--> Chloe_Trip\n",
      "    Related: Sister_Pet_Sitting <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Dog_Arlo\n",
      "    Related: Dog_Arlo --[has_behavior]--> Arlo_Anxiety\n",
      "    Related: Dog_Arlo --[cared_by]--> Sister_Pet_Sitting\n",
      "  Exploring from: Arlo_Anxiety\n",
      "    Related: Arlo_Anxiety <--[{relationship}]-- Dog_Arlo\n",
      "\n",
      "Step 3: Evaluating 7 candidates for relevance\n",
      "  LLM selected 3 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "1. Italian_Wedding: My friend's wedding is next month, and it's a traditional Italian feast.\n",
      "2. Italian_Food: Traditional Italian feasts often feature a lot of cheese and cream-based sauces.\n",
      "3. Lactose_Intolerance: I'm lactose intolerant and avoid dairy products strictly.\n",
      "\n",
      "======================================================================\n",
      " EXAMPLE 4: Is Japan a good destination for me?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'Is Japan a good destination for me?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Japan_Interest (similarity: 0.466)\n",
      "Found semantic match: Japan_Flight_Duration (similarity: 0.417)\n",
      "Found semantic match: Cherry_Blossom_Season (similarity: 0.305)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Japan_Interest\n",
      "    Related: Japan_Interest --[during]--> Cherry_Blossom_Season\n",
      "    Related: Japan_Interest --[limited_by]--> Flying_Fear\n",
      "  Exploring from: Japan_Flight_Duration\n",
      "    Related: Japan_Flight_Duration <--[{relationship}]-- Flying_Fear\n",
      "  Exploring from: Flying_Fear\n",
      "    Related: Flying_Fear --[triggered_by]--> Japan_Flight_Duration\n",
      "    Related: Flying_Fear <--[{relationship}]-- Japan_Interest\n",
      "  Exploring from: Cherry_Blossom_Season\n",
      "    Related: Cherry_Blossom_Season <--[{relationship}]-- Japan_Interest\n",
      "\n",
      "Step 3: Evaluating 4 candidates for relevance\n",
      "  LLM selected 4 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "1. Japan_Interest: I dream of visiting Japan for the cherry blossom season.\n",
      "2. Japan_Flight_Duration: Flights to Japan from my home are usually over 12 hours long.\n",
      "3. Flying_Fear: I'm quite scared of flying long distances.\n",
      "4. Cherry_Blossom_Season: Cherry blossom season in Japan is typically late March to April.\n",
      "\n",
      "======================================================================\n",
      " EXAMPLE 5: Anything I should know about my dog before I travel?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'Anything I should know about my dog before I travel?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Arlo_Anxiety (similarity: 0.314)\n",
      "Found semantic match: Sister_Pet_Sitting (similarity: 0.299)\n",
      "Found semantic match: Dog_Arlo (similarity: 0.298)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Arlo_Anxiety\n",
      "    Related: Arlo_Anxiety <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Sister_Pet_Sitting\n",
      "    Related: Sister_Pet_Sitting --[affected_by]--> Chloe_Trip\n",
      "    Related: Sister_Pet_Sitting <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Dog_Arlo\n",
      "    Related: Dog_Arlo --[has_behavior]--> Arlo_Anxiety\n",
      "    Related: Dog_Arlo --[cared_by]--> Sister_Pet_Sitting\n",
      "  Exploring from: Chloe_Trip\n",
      "    Related: Chloe_Trip <--[{relationship}]-- Sister_Pet_Sitting\n",
      "\n",
      "Step 3: Evaluating 4 candidates for relevance\n",
      "  LLM selected 3 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "1. Arlo_Anxiety: Arlo gets very anxious if left with strangers for too long.\n",
      "2. Sister_Pet_Sitting: I only trust my sister, Chloe, to watch Arlo when I travel.\n",
      "3. Chloe_Trip: Chloe is planning a big trip to Europe for all of July.\n",
      "\n",
      "======================================================================\n",
      " EXAMPLE 6: What are the best ways to learn Spanish quickly?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'What are the best ways to learn Spanish quickly?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Language_Learning (similarity: 0.667)\n",
      "Found semantic match: Learning_Spanish (similarity: 0.490)\n",
      "Found semantic match: Company_Expansion (similarity: 0.200)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Language_Learning\n",
      "    Related: Language_Learning <--[{relationship}]-- Learning_Spanish\n",
      "  Exploring from: Learning_Spanish\n",
      "    Related: Learning_Spanish --[method]--> Language_Learning\n",
      "    Related: Learning_Spanish <--[{relationship}]-- Company_Expansion\n",
      "  Exploring from: Company_Expansion\n",
      "    Related: Company_Expansion --[motivates]--> Learning_Spanish\n",
      "\n",
      "Step 3: Evaluating 3 candidates for relevance\n",
      "  LLM selected 2 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "1. Language_Learning: Immersion is the best way to learn a language quickly.\n",
      "2. Learning_Spanish: I want to learn Spanish to improve my career prospects.\n",
      "\n",
      "======================================================================\n",
      " EXAMPLE 7: What are the best hotels in Tokyo?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'What are the best hotels in Tokyo?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Expensive_Boutique (similarity: 0.352)\n",
      "Found semantic match: Hotel_Preference (similarity: 0.287)\n",
      "Found semantic match: Japan_Interest (similarity: 0.257)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Expensive_Boutique\n",
      "    Related: Expensive_Boutique <--[{relationship}]-- Hotel_Preference\n",
      "  Exploring from: Hotel_Preference\n",
      "    Related: Hotel_Preference --[relates_to]--> Expensive_Boutique\n",
      "    Related: Hotel_Preference <--[{relationship}]-- Travel_Budget\n",
      "  Exploring from: Japan_Interest\n",
      "    Related: Japan_Interest --[during]--> Cherry_Blossom_Season\n",
      "    Related: Japan_Interest --[limited_by]--> Flying_Fear\n",
      "  Exploring from: Travel_Budget\n",
      "    Related: Travel_Budget --[influences]--> Hotel_Preference\n",
      "  Exploring from: Cherry_Blossom_Season\n",
      "    Related: Cherry_Blossom_Season <--[{relationship}]-- Japan_Interest\n",
      "  Exploring from: Flying_Fear\n",
      "    Related: Flying_Fear --[triggered_by]--> Japan_Flight_Duration\n",
      "    Related: Flying_Fear <--[{relationship}]-- Japan_Interest\n",
      "  Exploring from: Japan_Flight_Duration\n",
      "    Related: Japan_Flight_Duration <--[{relationship}]-- Flying_Fear\n",
      "\n",
      "Step 3: Evaluating 7 candidates for relevance\n",
      "  LLM selected 3 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "1. Travel_Budget: I have a strict travel budget of $1000 for my next trip.\n",
      "2. Hotel_Preference: I prefer boutique hotels over large chain hotels.\n",
      "3. Japan_Interest: I dream of visiting Japan for the cherry blossom season.\n",
      "\n",
      "\n",
      "================================================================================\n",
      " HALLUCINATION TESTS (Should find no/minimal relevant memories)\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      " HALLUCINATION TEST 1: Tell me about my cat Felix.\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'Tell me about my cat Felix.'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Dog_Arlo (similarity: 0.267)\n",
      "Found semantic match: Sister_Pet_Sitting (similarity: 0.196)\n",
      "Found semantic match: Arlo_Anxiety (similarity: 0.191)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Dog_Arlo\n",
      "    Related: Dog_Arlo --[has_behavior]--> Arlo_Anxiety\n",
      "    Related: Dog_Arlo --[cared_by]--> Sister_Pet_Sitting\n",
      "  Exploring from: Sister_Pet_Sitting\n",
      "    Related: Sister_Pet_Sitting --[affected_by]--> Chloe_Trip\n",
      "    Related: Sister_Pet_Sitting <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Arlo_Anxiety\n",
      "    Related: Arlo_Anxiety <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Chloe_Trip\n",
      "    Related: Chloe_Trip <--[{relationship}]-- Sister_Pet_Sitting\n",
      "\n",
      "Step 3: Evaluating 4 candidates for relevance\n",
      "  LLM selected 0 relevant memories\n",
      "\n",
      "📋 RESULTS (Hallucination Test):\n",
      "✓ Correctly found no relevant memories - system did not hallucinate at the retrieval stage.\n",
      "\n",
      "======================================================================\n",
      " HALLUCINATION TEST 2: What car do I drive?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'What car do I drive?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Dog_Arlo (similarity: 0.139)\n",
      "Found semantic match: Learning_Spanish (similarity: 0.132)\n",
      "Found semantic match: Sister_Pet_Sitting (similarity: 0.115)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Dog_Arlo\n",
      "    Related: Dog_Arlo --[has_behavior]--> Arlo_Anxiety\n",
      "    Related: Dog_Arlo --[cared_by]--> Sister_Pet_Sitting\n",
      "  Exploring from: Learning_Spanish\n",
      "    Related: Learning_Spanish --[method]--> Language_Learning\n",
      "    Related: Learning_Spanish <--[{relationship}]-- Company_Expansion\n",
      "  Exploring from: Sister_Pet_Sitting\n",
      "    Related: Sister_Pet_Sitting --[affected_by]--> Chloe_Trip\n",
      "    Related: Sister_Pet_Sitting <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Arlo_Anxiety\n",
      "    Related: Arlo_Anxiety <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Language_Learning\n",
      "    Related: Language_Learning <--[{relationship}]-- Learning_Spanish\n",
      "  Exploring from: Company_Expansion\n",
      "    Related: Company_Expansion --[motivates]--> Learning_Spanish\n",
      "  Exploring from: Chloe_Trip\n",
      "    Related: Chloe_Trip <--[{relationship}]-- Sister_Pet_Sitting\n",
      "\n",
      "Step 3: Evaluating 7 candidates for relevance\n",
      "  LLM selected 0 relevant memories\n",
      "\n",
      "📋 RESULTS (Hallucination Test):\n",
      "✓ Correctly found no relevant memories - system did not hallucinate at the retrieval stage.\n",
      "\n",
      "======================================================================\n",
      " HALLUCINATION TEST 3: When is my mother's birthday?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'When is my mother's birthday?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Italian_Wedding (similarity: 0.200)\n",
      "Found semantic match: Chloe_Trip (similarity: 0.145)\n",
      "Found semantic match: Cherry_Blossom_Season (similarity: 0.118)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Italian_Wedding\n",
      "    Related: Italian_Wedding --[features]--> Italian_Food\n",
      "    Related: Italian_Wedding <--[{relationship}]-- Lactose_Intolerance\n",
      "  Exploring from: Italian_Food\n",
      "    Related: Italian_Food <--[{relationship}]-- Italian_Wedding\n",
      "  Exploring from: Lactose_Intolerance\n",
      "    Related: Lactose_Intolerance --[complicates]--> Italian_Wedding\n",
      "  Exploring from: Chloe_Trip\n",
      "    Related: Chloe_Trip <--[{relationship}]-- Sister_Pet_Sitting\n",
      "  Exploring from: Cherry_Blossom_Season\n",
      "    Related: Cherry_Blossom_Season <--[{relationship}]-- Japan_Interest\n",
      "  Exploring from: Sister_Pet_Sitting\n",
      "    Related: Sister_Pet_Sitting --[affected_by]--> Chloe_Trip\n",
      "    Related: Sister_Pet_Sitting <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Japan_Interest\n",
      "    Related: Japan_Interest --[during]--> Cherry_Blossom_Season\n",
      "    Related: Japan_Interest --[limited_by]--> Flying_Fear\n",
      "  Exploring from: Dog_Arlo\n",
      "    Related: Dog_Arlo --[has_behavior]--> Arlo_Anxiety\n",
      "    Related: Dog_Arlo --[cared_by]--> Sister_Pet_Sitting\n",
      "  Exploring from: Flying_Fear\n",
      "    Related: Flying_Fear --[triggered_by]--> Japan_Flight_Duration\n",
      "    Related: Flying_Fear <--[{relationship}]-- Japan_Interest\n",
      "  Exploring from: Arlo_Anxiety\n",
      "    Related: Arlo_Anxiety <--[{relationship}]-- Dog_Arlo\n",
      "\n",
      "Step 3: Evaluating 11 candidates for relevance\n",
      "  LLM selected 0 relevant memories\n",
      "\n",
      "📋 RESULTS (Hallucination Test):\n",
      "✓ Correctly found no relevant memories - system did not hallucinate at the retrieval stage.\n",
      "\n",
      "\n",
      "================================================================================\n",
      " TRUE FACT TESTS (Should find specific relevant memories)\n",
      "================================================================================\n",
      "\n",
      "======================================================================\n",
      " TRUE FACT TEST 1: Do I have any dietary restrictions?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'Do I have any dietary restrictions?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Lactose_Intolerance (similarity: 0.412)\n",
      "Found semantic match: Italian_Food (similarity: 0.256)\n",
      "Found semantic match: Italian_Wedding (similarity: 0.225)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Lactose_Intolerance\n",
      "    Related: Lactose_Intolerance --[complicates]--> Italian_Wedding\n",
      "  Exploring from: Italian_Food\n",
      "    Related: Italian_Food <--[{relationship}]-- Italian_Wedding\n",
      "  Exploring from: Italian_Wedding\n",
      "    Related: Italian_Wedding --[features]--> Italian_Food\n",
      "    Related: Italian_Wedding <--[{relationship}]-- Lactose_Intolerance\n",
      "\n",
      "Step 3: Evaluating 3 candidates for relevance\n",
      "  LLM selected 1 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "Found 1 memories:\n",
      "1. Lactose_Intolerance: I'm lactose intolerant and avoid dairy products strictly.\n",
      "✓ Correctly found all 1/1 expected memories.\n",
      "\n",
      "======================================================================\n",
      " TRUE FACT TEST 2: Tell me about Arlo.\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'Tell me about Arlo.'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Dog_Arlo (similarity: 0.581)\n",
      "Found semantic match: Arlo_Anxiety (similarity: 0.516)\n",
      "Found semantic match: Sister_Pet_Sitting (similarity: 0.414)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Dog_Arlo\n",
      "    Related: Dog_Arlo --[has_behavior]--> Arlo_Anxiety\n",
      "    Related: Dog_Arlo --[cared_by]--> Sister_Pet_Sitting\n",
      "  Exploring from: Arlo_Anxiety\n",
      "    Related: Arlo_Anxiety <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Sister_Pet_Sitting\n",
      "    Related: Sister_Pet_Sitting --[affected_by]--> Chloe_Trip\n",
      "    Related: Sister_Pet_Sitting <--[{relationship}]-- Dog_Arlo\n",
      "  Exploring from: Chloe_Trip\n",
      "    Related: Chloe_Trip <--[{relationship}]-- Sister_Pet_Sitting\n",
      "\n",
      "Step 3: Evaluating 4 candidates for relevance\n",
      "  LLM selected 3 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "Found 3 memories:\n",
      "1. Dog_Arlo: My dog Arlo is a golden retriever.\n",
      "2. Arlo_Anxiety: Arlo gets very anxious if left with strangers for too long.\n",
      "3. Sister_Pet_Sitting: I only trust my sister, Chloe, to watch Arlo when I travel.\n",
      "✓ Correctly found all 3/3 expected memories.\n",
      "\n",
      "======================================================================\n",
      " TRUE FACT TEST 3: What language am I learning?\n",
      "======================================================================\n",
      "\n",
      "Processing query: 'What language am I learning?'\n",
      "\n",
      "Step 1: Performing initial semantic search\n",
      "Found semantic match: Learning_Spanish (similarity: 0.430)\n",
      "Found semantic match: Language_Learning (similarity: 0.418)\n",
      "Found semantic match: Company_Expansion (similarity: 0.162)\n",
      "\n",
      "🔍 Step 2: Exploring graph from initial matches\n",
      "  Exploring from: Learning_Spanish\n",
      "    Related: Learning_Spanish --[method]--> Language_Learning\n",
      "    Related: Learning_Spanish <--[{relationship}]-- Company_Expansion\n",
      "  Exploring from: Language_Learning\n",
      "    Related: Language_Learning <--[{relationship}]-- Learning_Spanish\n",
      "  Exploring from: Company_Expansion\n",
      "    Related: Company_Expansion --[motivates]--> Learning_Spanish\n",
      "\n",
      "Step 3: Evaluating 3 candidates for relevance\n",
      "  LLM selected 1 relevant memories\n",
      "\n",
      "📋 RESULTS:\n",
      "Found 1 memories:\n",
      "1. Learning_Spanish: I want to learn Spanish to improve my career prospects.\n",
      "✓ Correctly found 1/2 expected memories. (Partially matched)\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------\n",
    "# 7. Example Usage with Hallucination and True Fact Tests\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup core memories if needed\n",
    "    setup_core_memories() # Assume setup_core_memories and retrieve_relevant_memories are defined elsewhere\n",
    "    \n",
    "    # Example queries\n",
    "    example_queries = [\n",
    "        \"Any ideas for a holiday in July?\",\n",
    "        \"I want to go scuba diving on my next vacation.\",\n",
    "        \"What should I know about attending my friend's Italian wedding?\",\n",
    "        \"Is Japan a good destination for me?\",\n",
    "        \"Anything I should know about my dog before I travel?\",\n",
    "        \"What are the best ways to learn Spanish quickly?\",\n",
    "        \"What are the best hotels in Tokyo?\",\n",
    "    ]\n",
    "    \n",
    "    # Tests for hallucination vs. true facts\n",
    "    hallucination_test_queries = [\n",
    "        \"Tell me about my cat Felix.\", # Hallucination test - no cat in KB\n",
    "        \"What car do I drive?\", # Hallucination test - no car info in KB\n",
    "        \"When is my mother's birthday?\", # Hallucination test - no family birthday info\n",
    "    ]\n",
    "    \n",
    "    true_fact_test_queries = [\n",
    "        \"Do I have any dietary restrictions?\", # True fact test - lactose intolerance exists\n",
    "        \"Tell me about Arlo.\", # True fact test - dog info exists\n",
    "        \"What language am I learning?\", # True fact test - Spanish learning exists\n",
    "    ]\n",
    "    \n",
    "    # Run all example queries\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" STANDARD EXAMPLES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, query in enumerate(example_queries, 1):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\" EXAMPLE {i}: {query}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Assuming retrieve_relevant_memories prints its own detailed processing steps\n",
    "        relevant_memories = retrieve_relevant_memories(query) \n",
    "        \n",
    "        print(\"\\n📋 RESULTS:\")\n",
    "        if relevant_memories:\n",
    "            for j, memory in enumerate(relevant_memories, 1):\n",
    "                print(f\"{j}. {memory['node_name']}: {memory['text']}\")\n",
    "        else:\n",
    "            print(\"No relevant memories found.\")\n",
    "    \n",
    "    # Run hallucination test queries\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\" HALLUCINATION TESTS (Should find no/minimal relevant memories)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, query in enumerate(hallucination_test_queries, 1):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\" HALLUCINATION TEST {i}: {query}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # retrieve_relevant_memories will print its internal processing, including the LLM filter step\n",
    "        relevant_memories = retrieve_relevant_memories(query) \n",
    "        \n",
    "        print(\"\\n📋 RESULTS (Hallucination Test):\") # Added context to title\n",
    "        if relevant_memories:\n",
    "            # This block is hit in the example output because retrieve_relevant_memories falls back\n",
    "            # to initial semantic matches when its LLM filter step has an issue or returns an empty list.\n",
    "            print(f\"⚠️ Initial retrieval found {len(relevant_memories)} memories for a query where no direct information is expected:\")\n",
    "            for j, memory in enumerate(relevant_memories, 1):\n",
    "                print(f\"  {j}. {memory['node_name']}: {memory['text']}\")\n",
    "            \n",
    "            # START :: Explicit marking for hallucination test results\n",
    "            print(f\"\\n   👉 EXPLICIT HALLUCINATION TEST for query: '{query}'\")\n",
    "            print(f\"   - Purpose: This query tests if the system avoids retrieving/generating information not present in its knowledge base.\")\n",
    "            print(f\"   - Memories Retrieved by Fallback: {len(relevant_memories)} (listed above). These were surfaced by initial search/graph steps but were intended to be filtered.\")\n",
    "            # The following line refers to the behavior observed in the problem's output:\n",
    "            # \"Step 3: Evaluating N candidates for relevance ... LLM response was: []\"\n",
    "            print(f\"   - Internal LLM Filter Verdict (Observed from retrieval logs): Indicated NO RELEVANT memories among candidates (e.g., via an empty list '[]' response from LLM).\")\n",
    "            print(f\"   - Reason for these memories being listed: They were likely returned due to a fallback mechanism in 'retrieve_relevant_memories' when the LLM filter step errored or yielded an empty relevance list.\")\n",
    "            print(f\"   - Assessment of Hallucination Risk:\")\n",
    "            print(f\"     - The LLM filter's *intended* action (to discard these candidates as irrelevant) was correct for avoiding hallucination.\")\n",
    "            print(f\"     - However, the *fallback mechanism* returning these initial candidates means that if a downstream agent were to use these specific memories *as is* to answer '{query}', it would likely lead to hallucination (providing irrelevant information).\")\n",
    "            print(f\"     - For a robust anti-hallucination setup, the retrieval should ideally return an empty list if the LLM filter definitively indicates no relevance, overriding any fallback to broader, unfiltered candidates.\")\n",
    "            # END :: Explicit marking for hallucination test results\n",
    "        else:\n",
    "            # This is the ideal outcome for a hallucination test at the retrieval stage.\n",
    "            # (This branch is not hit in the provided sample output for hallucination tests).\n",
    "            print(\"✓ Correctly found no relevant memories - system did not hallucinate at the retrieval stage.\")\n",
    "    \n",
    "    # Run true fact test queries\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\" TRUE FACT TESTS (Should find specific relevant memories)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, query in enumerate(true_fact_test_queries, 1):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\" TRUE FACT TEST {i}: {query}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        relevant_memories = retrieve_relevant_memories(query)\n",
    "        \n",
    "        print(\"\\n📋 RESULTS:\")\n",
    "        if relevant_memories:\n",
    "            print(f\"Found {len(relevant_memories)} memories:\")\n",
    "            for j, memory in enumerate(relevant_memories, 1):\n",
    "                print(f\"{j}. {memory['node_name']}: {memory['text']}\")\n",
    "            \n",
    "            expected_nodes = {\n",
    "                \"Do I have any dietary restrictions?\": [\"Lactose_Intolerance\"],\n",
    "                \"Tell me about Arlo.\": [\"Dog_Arlo\", \"Arlo_Anxiety\", \"Sister_Pet_Sitting\"],\n",
    "                \"What language am I learning?\": [\"Learning_Spanish\", \"Language_Learning\"]\n",
    "            }\n",
    "            \n",
    "            if query in expected_nodes:\n",
    "                found_expectations = [node for node in expected_nodes[query] \n",
    "                                     if any(m['node_name'] == node for m in relevant_memories)]\n",
    "                \n",
    "                # Check if all expected nodes are found\n",
    "                all_expected_found = len(found_expectations) == len(expected_nodes[query])\n",
    "                # Check if at least one expected node is found (original logic was > 0)\n",
    "                some_expected_found = len(found_expectations) > 0\n",
    "\n",
    "                if all_expected_found:\n",
    "                    print(f\"✓ Correctly found all {len(expected_nodes[query])}/{len(expected_nodes[query])} expected memories.\")\n",
    "                elif some_expected_found:\n",
    "                     print(f\"✓ Correctly found {len(found_expectations)}/{len(expected_nodes[query])} expected memories. (Partially matched)\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Did not find any of the expected memories: {expected_nodes[query]}\")\n",
    "                    # It's also useful to list what *was* found if it didn't match expectations,\n",
    "                    # but the current structure already lists all found memories above.\n",
    "        else:\n",
    "            print(\"⚠️ No relevant memories found - this is unexpected for a true fact test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7b377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ditto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
